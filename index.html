<!doctype html>
<html>
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

		<title>Snorkel BeamBell: Weak Supervision on Apache Flink</title>

    <meta name="description" content="Snorkel BeamBell: Weak Supervision on Apache Flink">
    <meta name="author" content="Suneel Marthi">

    <meta name="apple-mobile-web-app-capable" content="yes"/>
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent"/>

    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">

    <link rel="stylesheet" href="font-awesome-4.7.0/css/font-awesome.min.css">
		<link rel="stylesheet" href="css/reveal.css">
		<link rel="stylesheet" href="css/theme/bbuzz17.css">

		<!-- Theme used for syntax highlighting of code -->
		<link rel="stylesheet" href="lib/css/zenburn.css">

		<!-- Printing and PDF exports -->
		<script>
			var link = document.createElement( 'link' );
			link.rel = 'stylesheet';
			link.type = 'text/css';
			link.href = window.location.search.match( /print-pdf/gi ) ? 'css/print/pdf.css' : 'css/print/paper.css';
			document.getElementsByTagName( 'head' )[0].appendChild( link );
		</script>
    <!--[if lt IE 9]> <script src="lib/js/html5shiv.js"></script> <![endif]-->
	</head>
	<body>
		<div class="reveal">
			<div class="slides">
				<section data-background-image="img/brussels.jpg">
          <br/>
          <br/>
          <br/>
          <h3>Snorkel BeamBell: Weak Supervision on Apache Flink</h3>
          <br/>
          <p>Suneel Marthi</p>
          <p style="font-size: 60%">February 2, 2020<br/>
             FOSDEM, Brussels, Belgium</p>
        </section>
		<section data-background-image="img/ZsMwlm2.jpg">
          <h3>$WhoAmI</h3>
          <h6 style='text-align: left; font-size: 80%;'>Suneel Marthi <br/><span style="font-size: 60%"><i class="fa fa-twitter" aria-hidden="true"></i> @suneelmarthi</span></h6>
          <ul style='font-size: 70%;'>
            <li>Member of Apache Software Foundation</li>
            <li>Committer and PMC on Apache Mahout, Apache OpenNLP, Apache Streams</li>
          </ul>
        </section>
        <section data-background-image="img/ZsMwlm2.jpg">
          <h3>Agenda</h3>
          <ul>
            <li>What is Weak Supervision ?</li>
            <li>Why is it Needed?</li>
            <li>What problem does it solve?</li>
            <li>What are Learning Functions?</li>
            <li>Overview of Apache Beam</li>
            <li>Sample Use Cases</li>
          </ul>
        </section>
        <section data-background-image="img/ZsMwlm2-purpleish.jpg">
          <h3>OSS Tools</h3>
          <ul>
            <li>Snorkel - Framework for Programmatically Building and Managing Training Data</li>
            <li>Apache Beam - Unified model for defining both batch and streaming data-parallel processing pipelines</li>
            <li>Apache Flink - distributed processing engine for <b><span style="color: red">stateful</span></b> computations over data streams.</li>
          </ul>
        </section>
        <section data-background-image="img/ZsMwlm2-purpleish.jpg">
            <h3>Problem of Labeled Training Data</h3>
        </section>
        <section data-background-image="img/ZsMwlm2-greenish.jpg">
           <h3>Insufficient Labeled Data</h3>
            <p style='text-align: left'>Lack of Initial labeled training data to kick start Machine Learning models</p>
            <p style='text-align: left'>Lack of training data available over time unlike the big Internet companies</p>
            <p style='text-align: left'>Maybe many years in order to accummulate sufficient training data</p>
        </section>
        <section data-background-image="img/ZsMwlm2-yellowish.jpg">
            <h3>Lack of Subject Matter Expertise</h3>
            <p style='text-align: left'>Labeling training data requires necessary subject matter experise</p>
            <p style='text-align: left'>Labeling and managing training datasets by hand is one of the biggest bottlenecks in machine learning.</p>
            <p style='text-align: left'>Creation of labeled training data becomes prohibitively expensive and impossible when dealing with large datasets</p>
            <p style='font-size: 45%;'>For eg: Having to deal with datasets at Google Scale</p>
        </section>

        <section data-background-image="img/ZsMwlm2-purpleish.jpg">
            <h3>Possible Solutions</h3>
        </section>
        <section data-background-image="img/ZsMwlm2-purpleish.jpg">
            <h3>Weak Labels</h3>
            <p style='text-align: left'>Intent is to decrease the cost and increase the efficiency of human efforts expended
                in hand-labeling data.</p>
            <p style='text-align: left'>Leverage Subject Matter Expertise got less precise input to create heuristic rules for labeling data</p>
            <p style='font-size: 35%;'>"Data Programming: Creating Large Training Sets, Quickly" - Alexander Ratner, Christopher De Sa, Sen Wu, Daniel Selsam, Christopher Ré https://arxiv.org/pdf/1605.07723v3.pdf</p>
        </section>
        <section data-background-image="img/ZsMwlm2-redish.jpg">
            <h3>Lack of Subject Matter Expertise</h3>
            <p style='text-align: left'>Labeling training data requires necessary subject matter experise</p>
            <p style='text-align: left'>Creation of labeled training data becomes prohibitively expensive and impossible when dealing with large datasets</p>
        </section>

        <section data-background-image="img/ZsMwlm2-purpleish.jpg">
            <h3>What is Weak Supervision ?</h3>
        </section>
        <section data-background-image="img/ZsMwlm2-greenish.jpg">
            <dl>
                <dt>How to translate a word &rarr; lookup in dictionary</dt>
                <dd>Ge­b&auml;u­de — building, house, tower.</dd>
                <br/>
                <dt>Multiple translations</dt>
                <dd>some more frequent than others<br/>
                    for instance: house and building most common</dd>
            </dl>
        </section>
        <section data-background-image="img/ZsMwlm2-yellowish.jpg">
            <h3>Parallel Text</h3>
            <ul>
                <li>In a parallel text we align sentences in one language with the sentences in the other<br/>
                    <table>
                        <tr>
                            <td>Das</td><td>Geb&auml;ude</td><td>ist</td><td>hoch</td>
                        </tr>
                        <tr>
                            <td style='text-align: center;'>&darr;</td><td style='text-align: center;'>&darr;</td><td style='text-align: center;'>&darr;</td><td style='text-align: center;'>&darr;</td>
                        </tr>
                        <tr>
                            <td>the</td><td>building</td><td>is</td><td>high</td>
                        </tr>
                    </table>
                </li>
            </ul>
        </section>
        <section data-background-image="img/ZsMwlm2-blueish.jpg">
            <h3>Parallel Text</h3>
            <p>A source word could translate into multiple target words</p>
            <table>
                <tr>
                    <td>Das</td><td>ist</td><td>ein</td><td colspan='3' style='text-align: center;'>Hochhaus&nbsp;&nbsp;&nbsp;</td>
                </tr>
                <tr>
                    <td style='text-align: center;'>&darr;</td><td style='text-align: center;'>&darr;</td><td style='text-align: center;'>&darr;</td><td style='text-align: center;'>&#8601;</td><td style='text-align: center;'>&darr;</td><td style='text-align: center;'>&#8600;</td>
                </tr>
                <tr>
                    <td>This</td><td>is</td><td>a</td><td>high&nbsp;&nbsp;&nbsp;</td><td>rise</td><td>building</td>
                </tr>
            </table>
        </section>
        <section data-background-image="img/ZsMwlm2-purpleish.jpg">
            <h3>Neural Machine Translation</h3>
        </section>
       <section data-background-image="img/ZsMwlm2-purpleish.jpg">
            <p style='text-align: left'>Encoder Decoder Architecture</p>
            <div style="background: #c9c9c9;">
                <img src='img/gnmt_arch_1_enc_dec.svg' style='margin: 0px, 20px, 0px, 20px; border: none; background: none;box-shadow: none; '/>
            </div>
        </section>
        <section data-background-image="img/ZsMwlm2-purpleish.jpg">
            <p style='text-align: left'>Encoder Decoder Architecture with Attention</p>
            <div style="background: #c9c9c9;">
                <img src='img/Attention.png' style='margin: 0px, 20px, 0px, 20px; border: none; background: none;box-shadow: none; '/>
            </div>
        </section>
        <section data-background-image="img/ZsMwlm2-purpleish.jpg">
            <p style='text-align: left'>Transformer Model</p>
            <img src='img/transformer.png' style='max-width: 25%; margin: 0px, 20px, 0px, 20px; border: none; background: none;box-shadow: none; '/>
            <p style='font-size: 35%;'>"Attention Is All You Need" - Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, Illia Polosukhin <br/> Google Brain https://arxiv.org/abs/1706.03762</p>
        </section>
        <section data-background-image="img/ZsMwlm2-purpleish.jpg">
            <p style='text-align: left'>Generate Translations from Neural Network models trained on Bilingual Corpora.</p>
            <p style='text-align: left'>Translation happens per a probability distribution one word at time (no phrases).</p>
            <div style="background: #c9c9c9;">
                <img src='img/softmax.png' style='margin: 0px, 20px, 0px, 20px; border: none; background: none;box-shadow: none; '/><br/>
                <img src='img/cross_entropy.png' style='margin: 0px, 20px, 0px, 20px; border: none; background: none;box-shadow: none; '/>
            </div>
        </section>
        <section data-background-image="img/ZsMwlm2-redish.jpg">
          <h3>Why move from SMT to NMT?</h3>
          <img src='img/wmt.png' style='max-width: 50%; max-height: 50%; border: none; background: none;box-shadow: none; '/>
          <p style='font-size: 50%;'>The University of Edinburgh’s Neural MT Systems for WMT17 – Rico Sennrich, Alexandra Birch, Anna Currey, Ulrich Germann, Barry Haddow, Kenneth Heafield, Antonio Valerio Miceli Barone and Philip Williams.</p>
        </section>
        <section data-background-image="img/ZsMwlm2-redish.jpg">
          <h3>NMT Samples</h3>
        </section>
        <section data-background-image="img/ZsMwlm2-redish.jpg">
          <p>Jetzt LIVE: Abgeordnete debattieren über Zuspitzung des Syrien-Konflikts.</p>
          <p>last but not least, Members are debating the escalation of the Syrian conflict.</p>
        </section>
        <section data-background-image="img/ZsMwlm2-redish.jpg">
          <p>Sie haben wenig Zeit, wollen aber Fett verbrennen und Muskeln aufbauen?</p>
          <p>You have little time, but want to burn fat and build muscles?</p>
        </section>
        <section data-background-image="img/ZsMwlm2-redish.jpg">
          <h3>NMT Challenges – Twitter Content</h3>
          <img src='img/twitter_is_hard.png' style='max-width: 75%; max-height: 50%; border: none; background: none;box-shadow: none; '/>
        </section>
        <section data-background-image="img/ZsMwlm2-redish.jpg">
          <h3>NMT Challenges – Input</h3>
          <ul>
            <li>The input into all neural network models is always a vector.</li>
            <li>Training data is always parallel text.</li>
            <li>How do you represent a word from the text as a vector?</li>
          </ul>
        </section>
        <section data-background-image="img/ZsMwlm2-redish.jpg">
          <h3>Embedding Layer</h3>
          <img src='img/vocab_first.png' style='max-width: 100%; border: none; background: none;box-shadow: none; '/>
        </section>
        <section data-background-image="img/ZsMwlm2-redish.jpg">
          <img src='img/vocab_learned.png' style='max-width: 100%; border: none; background: none;box-shadow: none; '/>
        </section>
        <section data-background-image="img/ZsMwlm2-redish.jpg">
          <h3>NMT Challenges – Rare Words</h3>
          <p>Ok we can now represent 30,000 words as vectors, what about the rest?</p>
        </section>
        <section data-background-image="img/ZsMwlm2-redish.jpg">
          <h3>NMT Challenges – Byte Pair Encoding</h3>
          <img src='img/bpe.png' style='max-width: 65%; border: none; background: none;box-shadow: none; '/>
          <p style='font-size: 35%;'>Rico Sennrich, Barry Haddow and Alexandra Birch (2016): Neural Machine Translation of Rare Words with Subword Units Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (ACL 2016). Berlin, Germany.</p>
        </section>
        <section data-background-image="img/ZsMwlm2-redish.jpg">
          <h4>Byte Pair Encoding</h4>
          "positional addition contextual"
        </section>
        <section data-background-image="img/ZsMwlm2-redish.jpg">
          <h4>Byte Pair Encoding</h4>
          "posi<span style="color: red">X</span>onal addi<span style="color: red">X</span>on contextual"</br>
          ti = <span style="color: red">X</span>
        </section>
        <section data-background-image="img/ZsMwlm2-redish.jpg">
          <h4>Byte Pair Encoding</h4>
          "posi<span style="color: red">X</span>on<span style="color: blue">Y</span> addi<span style="color: red">X</span>on contextu<span style="color: blue">Y</span>"</br>
          ti = <span style="color: red">X</span></br>
          al = <span style="color: blue">Y</span>
        </section>
        <section data-background-image="img/ZsMwlm2-redish.jpg">
          <h4>Byte Pair Encoding</h4>
          "posi<span style="color: yellow">Z</span>n<span style="color: blue">Y</span> addi<span style="color: yellow">Z</span>n contextu<span style="color: blue">Y</span>"</br>
          ti = <span style="color: red">X</span></br>
          al = <span style="color: blue">Y</span></br>
          <span style="color: red">X</span>o = <span style="color: yellow">Z</span>
        </section>
        <section data-background-image="img/ZsMwlm2-redish.jpg">
          <h4>Byte Pair Encoding</h4>
          these<br/>
          ing<br/>
          other<br/>
          s,<br/>
          must<br/>
          Member
        </section>
        <section data-background-image="img/ZsMwlm2-redish.jpg">
          <h3>NMT Challenges – Jagged Tensors</h3>
          <p>Input is not sorted by length.</p>
        </section>
        <section data-background-image="img/ZsMwlm2-redish.jpg">
          <h3>Jagged Tensors cont.</h3>
          <img src='img/jagged.png' style='max-width: 80%; border: none; background: none;box-shadow: none; '/>
        </section>
        <section data-background-image="img/ZsMwlm2-redish.jpg">
          <h3>Jagged Tensors cont.</h3>
          <img src='img/sorted.png' style='max-width: 80%; border: none; background: none;box-shadow: none; '/>
        </section>
        <section data-background-image="img/ZsMwlm2-redish.jpg">
          <h3>Jagged Tensors cont.</h3>
          <img src='img/batch.png' style='max-width: 80%; border: none; background: none;box-shadow: none; '/>
        </section>
        <section data-background-image="img/ZsMwlm2-purpleish.jpg">
            <h3>Streaming Pipelines for NMT</h3>
        </section>

        <section data-background-image="img/ZsMwlm2-greenish.jpg">
            <h3>NMT Inference Preprocessing</h3>
            <img src='img/NMT_tasks.png' style='max-width: 80%; border: none; background: none;box-shadow: none; '/>
        </section>
        <section data-background-image="img/ZsMwlm2-greenish.jpg">
            <h3>Complete Pipeline (Flink)</h3>
            <img src='img/Complete-pipeline.png' style='max-width: 80%; border: none; background: none;box-shadow: none; '/>
        </section>
        <section data-background-image="img/ZsMwlm2-greenish.jpg">
            <h3>NMT Inference Pipeline</h3>
            <img src='img/pipeline.png' style='max-width: 80%; border: none; background: none;box-shadow: none; '/>
        </section>
        <section data-background-image="img/ZsMwlm2-greenish.jpg">
            <h3>Future Work</h3>
            <ul>
                <li>Train NMT models on real time streams</li>
                <li>Ideally ingest 2 similar streams in different languages to train NMT models</li>
                <li>Definitely feasible with Apache Flink Stateful Stream Processing</li>
                <li>Possible to do both Training and Inference using Flink's Broadcast State</li>
            </ul>
        </section>
        <section data-background-image="img/ZsMwlm2.jpg">
          <h2>Links</h2>
          <ul>
            <li>Snorkel: https://www.snorkel.org/</li>
            <li>Slides: https://smarthi.github.io/FOSDEM-2020/index.html#/</li>
            <li>Code: https://github.com/smarthi/streamingnmt</li>
          </ul>
        </section>
        <section data-background-image="img/ZsMwlm2.jpg">
          <h2>Gibt es Fragen ???</h2>
        </section>

			</div>
		</div>

		<script src="lib/js/head.min.js"></script>
		<script src="js/reveal.js"></script>

		<script>
			// More info about config & dependencies:
			// - https://github.com/hakimel/reveal.js#configuration
			// - https://github.com/hakimel/reveal.js#dependencies
			Reveal.initialize({
        controls: false,
        progress: true,
        history: true,
        center: true,
        slideNumber: true,
        transition: 'slide', // none/fade/slide/convex/concave/zoom
        keyboard: true,
        touch: true,
        loop: false,
        fragments: true,
				dependencies: [
					{ src: 'plugin/markdown/marked.js' },
					{ src: 'plugin/markdown/markdown.js' },
					{ src: 'plugin/notes/notes.js', async: true },
					{ src: 'plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } }
				]
			});
		</script>
	</body>
</html>
